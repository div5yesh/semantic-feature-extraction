{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8Cqqx_qZFb7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nrmqiuj8ECHr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pytorch_pretrained_bert"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gD2HA9wyDUIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from pandas import ExcelWriter\n",
        "from pandas import ExcelFile\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from read_data import Embeddings\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tlFhlHdDiHM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "b7ecc89f-54fc-4ed4-c99f-16d408ac04f1"
      },
      "source": [
        "df = pd.read_excel('./CONCS_FEATS_concstats_brm.xlsx')\n",
        "embeds = Embeddings()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 909247.05B/s]\n",
            "100%|██████████| 407873900/407873900 [00:15<00:00, 26919399.78B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YljCpw79Djjp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "concepts = list(df[[\"Concept\",\"Feature\"]].groupby(\"Concept\").groups.keys())\n",
        "features = list(df[[\"Concept\",\"Feature\"]].groupby(\"Concept\")[\"Feature\"].apply(list))\n",
        "\n",
        "dict_features = []\n",
        "for feat in features:\n",
        "    dict_features += [dict.fromkeys(feat, True)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItRwOngpDlfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dv = DictVectorizer(sparse=False)\n",
        "Y = dv.fit_transform(dict_features)\n",
        "Y = torch.tensor(Y).double()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBMSkqTUDm-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings = []\n",
        "for con in concepts:\n",
        "    em = embeds.getEmbeddings(con.split(\"_\")[0]).tolist()\n",
        "    embeddings.append(em)\n",
        "\n",
        "embeddings = torch.tensor(embeddings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrWOZqUWxNLZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(x): return 1/(1 + (-x).exp())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftFy5-HuDo1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(12 * 768, 300)\n",
        "        self.fc2 = nn.Linear(300, 100)\n",
        "        self.fc3 = nn.Linear(100, 2526)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 12 * 768)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        # x = F.softmax(x)\n",
        "        # F.log_softmax(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8y5W1G6Drs8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "5eeee7f2-5cda-46ee-88f4-b6a7442fa210"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "print(torch.cuda.get_device_name(device))\n",
        "net = Net()\n",
        "net.to(device)\n",
        "net.double()\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.2)\n",
        "pos_weight = (torch.ones(Y.shape[1])*3).double()\n",
        "criterion = nn.BCELoss(weight=pos_weight)\n",
        "criterion.to(device)"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BCELoss()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4RALg3PJNLS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def BCE_mod(pred, label):\n",
        "  eps = 1e-12\n",
        "  # print(pred)\n",
        "  cl = pred.clone()  \n",
        "  cl[cl >= 0.5] = 1\n",
        "  cl[cl < 0.5] = 0\n",
        "  # print(cl.shape)\n",
        "  pred_id = np.where(np.asarray(label.flatten().tolist()) == 1)[0]\n",
        "  \n",
        "  ownloss = cl-label  \n",
        "  ownloss[ownloss == -1] = 1\n",
        "  # ownloss=-(label*pred.clamp(min=eps).log()+(1-label)*(1-pred).clamp(min=eps).log()).mean()  \n",
        "  return ownloss.sum()/ownloss.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3RN3RBnDtmp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings = embeddings.double()\n",
        "trainX = embeddings[:449]\n",
        "devX = embeddings[450:499]\n",
        "testX = embeddings[500:]\n",
        "\n",
        "trainY = Y[:449]\n",
        "devY = Y[450:499]\n",
        "testY = Y[500:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZMWynNzDvou",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "646e016d-c664-4a81-d901-fcb594b44413"
      },
      "source": [
        "epochs = 200\n",
        "batch_size = 8\n",
        "run_loss = []\n",
        "batches = int(len(trainX)/batch_size)\n",
        "print(batches)\n",
        "for epoch in range(epochs):\n",
        "    for batch_idx in range(batches):\n",
        "        start = batch_size * batch_idx\n",
        "        end = batch_size * (batch_idx + 1)\n",
        "        # data, target = Variable(trainX[start:end]), Variable(trainY[start:end])​\n",
        "        data, target = Variable(trainX[start:end]), Variable(trainY[start:end])\n",
        "        if torch.cuda.is_available():\n",
        "            data, target = data.to(device), target.to(device)\n",
        "        # print(data.shape, target.shape)\n",
        "        # resize data from (batch_size, 1, 28, 28) to (batch_size, 28*28)\n",
        "        # data = data.view(-1, 12*768)\n",
        "        optimizer.zero_grad()\n",
        "        net_out = net(data)\n",
        "        # print(net_out)\n",
        "        # cl_out = net_out.clone()    \n",
        "        # cl_out[cl_out < 0.5] = 0\n",
        "        # cl_out[cl_out >= 0.5] = 1        \n",
        "        loss = criterion(net_out.reshape((-1,2526)), target.reshape((-1,2526)))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    if epoch%2 == 0:\n",
        "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, start , len(trainX),\n",
        "                        100. * batch_idx / len(trainX), loss.data))\n",
        "    run_loss.append(loss.item())"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "56\n",
            "Train Epoch: 0 [440/449 (12%)]\tLoss: 2.081525\n",
            "Train Epoch: 2 [440/449 (12%)]\tLoss: 2.077747\n",
            "Train Epoch: 4 [440/449 (12%)]\tLoss: 2.074954\n",
            "Train Epoch: 6 [440/449 (12%)]\tLoss: 2.072405\n",
            "Train Epoch: 8 [440/449 (12%)]\tLoss: 2.069994\n",
            "Train Epoch: 10 [440/449 (12%)]\tLoss: 2.067652\n",
            "Train Epoch: 12 [440/449 (12%)]\tLoss: 2.065330\n",
            "Train Epoch: 14 [440/449 (12%)]\tLoss: 2.063022\n",
            "Train Epoch: 16 [440/449 (12%)]\tLoss: 2.060683\n",
            "Train Epoch: 18 [440/449 (12%)]\tLoss: 2.058263\n",
            "Train Epoch: 20 [440/449 (12%)]\tLoss: 2.055712\n",
            "Train Epoch: 22 [440/449 (12%)]\tLoss: 2.053003\n",
            "Train Epoch: 24 [440/449 (12%)]\tLoss: 2.050084\n",
            "Train Epoch: 26 [440/449 (12%)]\tLoss: 2.046929\n",
            "Train Epoch: 28 [440/449 (12%)]\tLoss: 2.043507\n",
            "Train Epoch: 30 [440/449 (12%)]\tLoss: 2.039786\n",
            "Train Epoch: 32 [440/449 (12%)]\tLoss: 2.035736\n",
            "Train Epoch: 34 [440/449 (12%)]\tLoss: 2.031332\n",
            "Train Epoch: 36 [440/449 (12%)]\tLoss: 2.026558\n",
            "Train Epoch: 38 [440/449 (12%)]\tLoss: 2.021378\n",
            "Train Epoch: 40 [440/449 (12%)]\tLoss: 2.015757\n",
            "Train Epoch: 42 [440/449 (12%)]\tLoss: 2.009642\n",
            "Train Epoch: 44 [440/449 (12%)]\tLoss: 2.002987\n",
            "Train Epoch: 46 [440/449 (12%)]\tLoss: 1.995734\n",
            "Train Epoch: 48 [440/449 (12%)]\tLoss: 1.987816\n",
            "Train Epoch: 50 [440/449 (12%)]\tLoss: 1.979162\n",
            "Train Epoch: 52 [440/449 (12%)]\tLoss: 1.969689\n",
            "Train Epoch: 54 [440/449 (12%)]\tLoss: 1.959316\n",
            "Train Epoch: 56 [440/449 (12%)]\tLoss: 1.947946\n",
            "Train Epoch: 58 [440/449 (12%)]\tLoss: 1.935472\n",
            "Train Epoch: 60 [440/449 (12%)]\tLoss: 1.921786\n",
            "Train Epoch: 62 [440/449 (12%)]\tLoss: 1.906759\n",
            "Train Epoch: 64 [440/449 (12%)]\tLoss: 1.890249\n",
            "Train Epoch: 66 [440/449 (12%)]\tLoss: 1.872100\n",
            "Train Epoch: 68 [440/449 (12%)]\tLoss: 1.852128\n",
            "Train Epoch: 70 [440/449 (12%)]\tLoss: 1.830142\n",
            "Train Epoch: 72 [440/449 (12%)]\tLoss: 1.805929\n",
            "Train Epoch: 74 [440/449 (12%)]\tLoss: 1.779244\n",
            "Train Epoch: 76 [440/449 (12%)]\tLoss: 1.749818\n",
            "Train Epoch: 78 [440/449 (12%)]\tLoss: 1.717352\n",
            "Train Epoch: 80 [440/449 (12%)]\tLoss: 1.681514\n",
            "Train Epoch: 82 [440/449 (12%)]\tLoss: 1.641936\n",
            "Train Epoch: 84 [440/449 (12%)]\tLoss: 1.598222\n",
            "Train Epoch: 86 [440/449 (12%)]\tLoss: 1.549930\n",
            "Train Epoch: 88 [440/449 (12%)]\tLoss: 1.496595\n",
            "Train Epoch: 90 [440/449 (12%)]\tLoss: 1.437737\n",
            "Train Epoch: 92 [440/449 (12%)]\tLoss: 1.372867\n",
            "Train Epoch: 94 [440/449 (12%)]\tLoss: 1.301534\n",
            "Train Epoch: 96 [440/449 (12%)]\tLoss: 1.223369\n",
            "Train Epoch: 98 [440/449 (12%)]\tLoss: 1.138175\n",
            "Train Epoch: 100 [440/449 (12%)]\tLoss: 1.046055\n",
            "Train Epoch: 102 [440/449 (12%)]\tLoss: 0.947605\n",
            "Train Epoch: 104 [440/449 (12%)]\tLoss: 0.844137\n",
            "Train Epoch: 106 [440/449 (12%)]\tLoss: 0.737883\n",
            "Train Epoch: 108 [440/449 (12%)]\tLoss: 0.632156\n",
            "Train Epoch: 110 [440/449 (12%)]\tLoss: 0.531197\n",
            "Train Epoch: 112 [440/449 (12%)]\tLoss: 0.439593\n",
            "Train Epoch: 114 [440/449 (12%)]\tLoss: 0.361212\n",
            "Train Epoch: 116 [440/449 (12%)]\tLoss: 0.298039\n",
            "Train Epoch: 118 [440/449 (12%)]\tLoss: 0.249685\n",
            "Train Epoch: 120 [440/449 (12%)]\tLoss: 0.213943\n",
            "Train Epoch: 122 [440/449 (12%)]\tLoss: 0.187916\n",
            "Train Epoch: 124 [440/449 (12%)]\tLoss: 0.168935\n",
            "Train Epoch: 126 [440/449 (12%)]\tLoss: 0.154936\n",
            "Train Epoch: 128 [440/449 (12%)]\tLoss: 0.144443\n",
            "Train Epoch: 130 [440/449 (12%)]\tLoss: 0.136439\n",
            "Train Epoch: 132 [440/449 (12%)]\tLoss: 0.130226\n",
            "Train Epoch: 134 [440/449 (12%)]\tLoss: 0.125322\n",
            "Train Epoch: 136 [440/449 (12%)]\tLoss: 0.121392\n",
            "Train Epoch: 138 [440/449 (12%)]\tLoss: 0.118200\n",
            "Train Epoch: 140 [440/449 (12%)]\tLoss: 0.115574\n",
            "Train Epoch: 142 [440/449 (12%)]\tLoss: 0.113390\n",
            "Train Epoch: 144 [440/449 (12%)]\tLoss: 0.111554\n",
            "Train Epoch: 146 [440/449 (12%)]\tLoss: 0.109996\n",
            "Train Epoch: 148 [440/449 (12%)]\tLoss: 0.108660\n",
            "Train Epoch: 150 [440/449 (12%)]\tLoss: 0.107505\n",
            "Train Epoch: 152 [440/449 (12%)]\tLoss: 0.106498\n",
            "Train Epoch: 154 [440/449 (12%)]\tLoss: 0.105613\n",
            "Train Epoch: 156 [440/449 (12%)]\tLoss: 0.104829\n",
            "Train Epoch: 158 [440/449 (12%)]\tLoss: 0.104130\n",
            "Train Epoch: 160 [440/449 (12%)]\tLoss: 0.103503\n",
            "Train Epoch: 162 [440/449 (12%)]\tLoss: 0.102936\n",
            "Train Epoch: 164 [440/449 (12%)]\tLoss: 0.102420\n",
            "Train Epoch: 166 [440/449 (12%)]\tLoss: 0.101948\n",
            "Train Epoch: 168 [440/449 (12%)]\tLoss: 0.101514\n",
            "Train Epoch: 170 [440/449 (12%)]\tLoss: 0.101112\n",
            "Train Epoch: 172 [440/449 (12%)]\tLoss: 0.100738\n",
            "Train Epoch: 174 [440/449 (12%)]\tLoss: 0.100388\n",
            "Train Epoch: 176 [440/449 (12%)]\tLoss: 0.100059\n",
            "Train Epoch: 178 [440/449 (12%)]\tLoss: 0.099750\n",
            "Train Epoch: 180 [440/449 (12%)]\tLoss: 0.099456\n",
            "Train Epoch: 182 [440/449 (12%)]\tLoss: 0.099178\n",
            "Train Epoch: 184 [440/449 (12%)]\tLoss: 0.098913\n",
            "Train Epoch: 186 [440/449 (12%)]\tLoss: 0.098661\n",
            "Train Epoch: 188 [440/449 (12%)]\tLoss: 0.098420\n",
            "Train Epoch: 190 [440/449 (12%)]\tLoss: 0.098189\n",
            "Train Epoch: 192 [440/449 (12%)]\tLoss: 0.097967\n",
            "Train Epoch: 194 [440/449 (12%)]\tLoss: 0.097753\n",
            "Train Epoch: 196 [440/449 (12%)]\tLoss: 0.097547\n",
            "Train Epoch: 198 [440/449 (12%)]\tLoss: 0.097348\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXTJNbY3E6f8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "31ad4b92-0d3a-43e3-9180-f3147e23675b"
      },
      "source": [
        "print(\"Target:\",np.where(np.asarray(target[0].tolist()) == 1.0000)[0])\n",
        "print(\"Max in net_out:\",max(np.asarray(net_out[0].tolist())))\n",
        "print(\"net_out where 1:\",np.where(np.asarray(net_out[0].tolist()) >= 0.1)[0])\n",
        "print(\"net_out\", np.argsort(np.asarray(net_out[0].tolist()))[:15])"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target: [ 375 1251 1260 1592 1598 1617 1765 1817 2226 2280 2351 2378]\n",
            "Max in net_out: 0.22671785373336362\n",
            "net_out where 1: [ 151 1239 1293 1299 1355 1378 1592 1617]\n",
            "net_out [1709 1287  167 2444 1593  971 2501 1146  415 1826  192 2042  510 1511\n",
            " 1297]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2kstwrqTgVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDaXstVzTkve",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "5c0f7776-5d99-49ec-d4e9-7442b4f6e84b"
      },
      "source": [
        "plt.title(\"Loss curve - training\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(list(range(0,epochs)), run_loss)"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd55c138da0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 240
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tacNkzWDx2P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "34a01c91-d661-4857-9a35-b397f50b2f24"
      },
      "source": [
        "test_loss = 0\n",
        "correct = 0\n",
        "precision = 0\n",
        "threshold = 0.99\n",
        "recall = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    data, target = Variable(devX), Variable(devY)\n",
        "    if torch.cuda.is_available():\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "    net_out = net(data)\n",
        "    test_loss += criterion(net_out, target).data\n",
        "    out = net_out.data\n",
        "    x = out.clone()\n",
        "    # print(out.min(axis=1))    \n",
        "    out[out > 0.12] = 1\n",
        "    out[out <= 0.12] = 0\n",
        "\n",
        "for idx, act in enumerate(target):\n",
        "    pred = out[idx]\n",
        "    \n",
        "    match = sum((pred == act) * 1)\n",
        "\n",
        "    if match.tolist()/2526 >= threshold:\n",
        "        correct += 1    \n",
        "\n",
        "    idx_pred = np.where(np.array(out[idx].tolist()) == 1)\n",
        "    idx_act = np.where(np.array(target[idx].tolist()) == 1)\n",
        "\n",
        "    if idx == 35:\n",
        "      print(concepts[idx])\n",
        "      print(np.asarray(dv.get_feature_names())[idx_pred])\n",
        "      print(np.asarray(dv.get_feature_names())[idx_act])\n",
        "\n",
        "    tn_fp = out[idx].sum()\n",
        "    tn_tp = target[idx].sum()\n",
        "\n",
        "    precision += len(np.intersect1d(idx_act, idx_pred))/tn_fp\n",
        "    recall += len(np.intersect1d(idx_act, idx_pred))/tn_tp\n",
        "\n",
        "\n",
        "print(\"Accuracy:\", correct/len(devX))\n",
        "print(\"Precision:\", precision/len(devX))\n",
        "print(\"Recall:\", recall/len(devX))\n"
      ],
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bedroom\n",
            "['an_animal' 'different_colours' 'is_brown' 'is_edible' 'is_large'\n",
            " 'is_long' 'is_round' 'is_small' 'is_white' 'made_of_metal' 'made_of_wood']\n",
            "['clothing' 'different_colours' 'eg_-_bow' 'has_a_knot' 'has_patterns'\n",
            " 'is_businesslike' 'is_formal' 'is_long' 'is_thin' 'made_of_material'\n",
            " 'made_of_silk' 'worn_around_neck' 'worn_by_men' 'worn_with_suits']\n",
            "Accuracy: 0.9387755102040817\n",
            "Precision: tensor(0.1709, device='cuda:0', dtype=torch.float64)\n",
            "Recall: tensor(0.1089, device='cuda:0', dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9MFtJ79Rgvr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "9bdde41f-af4a-43f5-836f-0ab196f7a629"
      },
      "source": [
        "print(max(x[0].tolist()))\n",
        "print(min(x[0].tolist()))\n",
        "print((max(x[0].tolist())-min(x[0].tolist()))/2)\n",
        "a = (x.max()-x.min())/2\n",
        "print(a.item())"
      ],
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.244757244019339\n",
            "9.306159279937718e-10\n",
            "0.12237862154436153\n",
            "0.13491462261700765\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgDoT07GZL1w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "1c0fb582-6127-4618-caac-959d66fa9608"
      },
      "source": [
        "print(concepts[idx])\n",
        "print(np.asarray(dv.get_feature_names())[idx_pred])\n",
        "print(np.asarray(dv.get_feature_names())[idx_act])"
      ],
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "blouse\n",
            "['an_animal' 'is_edible' 'is_large' 'is_small' 'made_of_metal'\n",
            " 'made_of_wood']\n",
            "['found_in_cafeterias' 'is_flat' 'is_rectangular' 'is_round' 'is_square'\n",
            " 'made_of_metal' 'made_of_plastic' 'used_by_waitresses'\n",
            " 'used_for_carrying_drinks' 'used_for_carrying_things' 'used_for_food'\n",
            " 'used_for_holding_things']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfQ3ylxnQVl0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label = torch.tensor([1,0,0,0,1,0,0], dtype=torch.float64)\n",
        "pred = torch.tensor([0,0,1,0,1,0,0], dtype=torch.float64)\n",
        "eps = 1e-12\n",
        "ownloss=-(label*pred.clamp(min=eps).log()+(1-label)*(1-pred).clamp(min=eps).log()).mean()\n",
        "print(ownloss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntIhp4Dxngs2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans = pred-label\n",
        "ans[ans == -1] = 1\n",
        "print(\"LOSS:\", ans.sum()/ans.shape[0])\n",
        "# number of ones are the incorrect predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftZqEprVV8r7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = Variable(torch.randn(10, 120).float())\n",
        "target = Variable(label.uniform_(0, 7).long())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSxModUGWFqG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}